# ingest_orphaned_images.py
import os
import uuid
import chromadb
from chromadb.config import Settings
from tqdm import tqdm
from config import VECTOR_DB_PATH, COLLECTION_NAME, STATIC_DIR, OPENAI_API_KEY, OPENAI_API_BASE, OPENAI_EMBEDDING_MODEL
from openai import OpenAI

def ingest_images():
    print("ğŸš€ å¼€å§‹æ‰«æç¡¬ç›˜ä¸Šçš„å­¤å„¿å›¾ç‰‡ï¼Œå¹¶å°†å…¶æ³¨å†Œåˆ°æ•°æ®åº“...")
    
    # 1. åˆå§‹åŒ–
    client = chromadb.PersistentClient(path=VECTOR_DB_PATH, settings=Settings(anonymized_telemetry=False))
    collection = client.get_or_create_collection(COLLECTION_NAME)
    
    # åˆå§‹åŒ– Embedding å®¢æˆ·ç«¯ (è™½ç„¶ä¸ç”¨è§†è§‰æ¨¡å‹ï¼Œä½†å­˜å…¥æ•°æ®åº“å¿…é¡»è¦æœ‰å‘é‡ï¼Œè¿™ä¸ªå¾ˆä¾¿å®œ)
    openai_client = OpenAI(api_key=OPENAI_API_KEY, base_url=OPENAI_API_BASE)

    # 2. æ‰«æç¡¬ç›˜ä¸Šçš„æ‰€æœ‰å›¾ç‰‡
    image_files = []
    for root, _, files in os.walk(STATIC_DIR):
        for file in files:
            if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                full_path = os.path.join(root, file)
                # è½¬æ¢ä¸ºç›¸å¯¹è·¯å¾„
                rel_path = os.path.relpath(full_path, start=".")
                image_files.append({
                    "filename": file,
                    "path": rel_path.replace("\\", "/"), # ç»Ÿä¸€æ­£æ–œæ 
                    "theme": os.path.basename(root) # ç”¨æ–‡ä»¶å¤¹åä½œä¸ºä¸»é¢˜
                })

    print(f"ğŸ“‚ ç¡¬ç›˜ä¸Šå…±æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡ã€‚")

    # 3. å‡†å¤‡å…¥åº“æ•°æ®
    ids = []
    documents = []
    metadatas = []
    
    print("âš™ï¸ æ­£åœ¨ç”Ÿæˆæ•°æ®ç»“æ„...")
    for img in image_files:
        # âš ï¸ å…³é”®æŠ˜ä¸­ï¼šå› ä¸ºä¸æƒ³èŠ±é’±è°ƒ Vision APIï¼Œæˆ‘ä»¬ç”¨æ–‡ä»¶åä½œä¸º content
        # è¿™æ ·è‡³å°‘èƒ½ä¿è¯æ•°æ®å…¥åº“ï¼Œä¸”èƒ½åœ¨å‰ç«¯æ˜¾ç¤ºã€‚
        # æœç´¢æ•ˆæœå®Œå…¨ä¾èµ–äºæ–‡ä»¶åçš„è´¨é‡ã€‚
        description = f"ã€å›¾ç‰‡èµ„æºã€‘ æ–‡ä»¶å: {img['filename']} (æ‰€å±ä¸»é¢˜: {img['theme']})"
        
        ids.append(str(uuid.uuid4()))
        documents.append(description)
        metadatas.append({
            "filename": img["filename"],
            "image_path": img["path"],   # âœ… è¿™å°±æ˜¯å‰ç«¯éœ€è¦çš„æŒ‡è·¯ç‰Œ
            "is_image": True,            # âœ… è¿™å°±æ˜¯ check_database éœ€è¦çš„æ ‡è®°
            "page_number": 1,
            "chunk_id": "img_manual_ingest"
        })

    # 4. æ‰¹é‡ Embedding å¹¶å†™å…¥ (è¿™æ˜¯æœ€ä¾¿å®œçš„ text-embedding-v4)
    batch_size = 10
    total = len(documents)
    
    print(f"ğŸ’¾ æ­£åœ¨å†™å…¥æ•°æ®åº“ (å…± {total} æ¡)...")
    
    for i in tqdm(range(0, total, batch_size)):
        batch_docs = documents[i : i + batch_size]
        batch_ids = ids[i : i + batch_size]
        batch_metas = metadatas[i : i + batch_size]
        
        try:
            # è·å–æ–‡æœ¬å‘é‡ (éå¸¸ä¾¿å®œ)
            resp = openai_client.embeddings.create(input=batch_docs, model=OPENAI_EMBEDDING_MODEL)
            batch_embeddings = [d.embedding for d in resp.data]
            
            collection.add(
                ids=batch_ids,
                embeddings=batch_embeddings,
                documents=batch_docs,
                metadatas=batch_metas
            )
        except Exception as e:
            print(f"âŒ æ‰¹æ¬¡ {i} å†™å…¥å¤±è´¥: {e}")

    print("ğŸ‰ å®Œæˆï¼è¿™ 382 å¼ å›¾ç‰‡ç°åœ¨å·²ç»åœ¨æ•°æ®åº“é‡Œäº†ã€‚")
    print("ğŸ‘‰ è¯·é‡å¯ Chainlitï¼Œç°åœ¨åº”è¯¥èƒ½çœ‹åˆ°å›¾ç‰‡äº†ã€‚")

if __name__ == "__main__":
    ingest_images()